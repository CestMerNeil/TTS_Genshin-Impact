{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VitsConfig(output_path='/Users/neil/Code/TTS_GI/outputs', logger_uri=None, run_name='VITS_Kamisato_Ayaka', project_name=None, run_description='VITS Kamisato Ayaka / Genshin Impact', print_step=1, plot_step=100, model_param_stats=False, wandb_entity=None, dashboard_logger='tensorboard', save_on_interrupt=True, log_model_step=None, save_step=10000, save_n_checkpoints=5, save_checkpoints=True, save_all_best=False, save_best_after=0, target_loss=None, print_eval=True, test_delay_epochs=-1, run_eval=True, run_eval_steps=None, distributed_backend='nccl', distributed_url='tcp://localhost:54321', mixed_precision=True, precision='fp16', epochs=1, batch_size=16, eval_batch_size=16, grad_clip=[1000, 1000], scheduler_after_epoch=True, lr=0.001, optimizer='AdamW', optimizer_params={'betas': [0.8, 0.99], 'eps': 1e-09, 'weight_decay': 0.01}, lr_scheduler=None, lr_scheduler_params={}, use_grad_scaler=False, allow_tf32=False, cudnn_enable=True, cudnn_deterministic=False, cudnn_benchmark=True, training_seed=54321, model='vits', num_loader_workers=8, num_eval_loader_workers=8, use_noise_augment=True, audio=VitsAudioConfig(fft_size=1024, sample_rate=16000, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0.0, mel_fmax=None), use_phonemes=True, phonemizer=None, phoneme_language='zn-ch', compute_input_seq_cache=True, text_cleaner='chinese_cleaners', enable_eos_bos_chars=False, test_sentences_file='', phoneme_cache_path=None, characters=None, add_blank=True, batch_group_size=1, loss_masking=None, min_audio_len=1, max_audio_len=inf, min_text_len=1, max_text_len=inf, compute_f0=False, compute_energy=False, compute_linear_spec=True, precompute_num_workers=0, start_by_longest=False, shuffle=False, drop_last=False, datasets=[BaseDatasetConfig(formatter='ljspeech', dataset_name='', path='/Users/neil/Code/TTS_GI/dataset', meta_file_train='metadata.csv', ignored_speakers=None, language='', phonemizer='', meta_file_val='', meta_file_attn_mask='')], test_sentences=[['你好啊，小唐，你今天过的开心么？'], ['好久没有联系啦，你最近还好吗？'], ['我最近在学习新的技术，感觉很有趣。']], eval_split_max_size=None, eval_split_size=0.01, use_speaker_weighted_sampler=False, speaker_weighted_sampler_alpha=1.0, use_language_weighted_sampler=False, language_weighted_sampler_alpha=1.0, use_length_weighted_sampler=False, length_weighted_sampler_alpha=1.0, model_args=VitsArgs(num_chars=100, out_channels=513, spec_segment_size=32, hidden_channels=192, hidden_channels_ffn_text_encoder=768, num_heads_text_encoder=2, num_layers_text_encoder=6, kernel_size_text_encoder=3, dropout_p_text_encoder=0.1, dropout_p_duration_predictor=0.5, kernel_size_posterior_encoder=5, dilation_rate_posterior_encoder=1, num_layers_posterior_encoder=16, kernel_size_flow=5, dilation_rate_flow=1, num_layers_flow=4, resblock_type_decoder='1', resblock_kernel_sizes_decoder=[3, 7, 11], resblock_dilation_sizes_decoder=[[1, 3, 5], [1, 3, 5], [1, 3, 5]], upsample_rates_decoder=[8, 8, 2, 2], upsample_initial_channel_decoder=512, upsample_kernel_sizes_decoder=[16, 16, 4, 4], periods_multi_period_discriminator=[2, 3, 5, 7, 11], use_sdp=True, noise_scale=1.0, inference_noise_scale=0.667, length_scale=1, noise_scale_dp=1.0, inference_noise_scale_dp=1.0, max_inference_len=None, init_discriminator=True, use_spectral_norm_disriminator=False, use_speaker_embedding=False, num_speakers=0, speakers_file=None, d_vector_file=None, speaker_embedding_channels=256, use_d_vector_file=False, d_vector_dim=0, detach_dp_input=True, use_language_embedding=False, embedded_language_dim=4, num_languages=0, language_ids_file=None, use_speaker_encoder_as_loss=False, speaker_encoder_config_path='', speaker_encoder_model_path='', condition_dp_on_speaker=True, freeze_encoder=False, freeze_DP=False, freeze_PE=False, freeze_flow_decoder=False, freeze_waveform_decoder=False, encoder_sample_rate=None, interpolate_z=True, reinit_DP=False, reinit_text_encoder=False), lr_gen=0.0002, lr_disc=0.0002, lr_scheduler_gen='ExponentialLR', lr_scheduler_gen_params={'gamma': 0.999875, 'last_epoch': -1}, lr_scheduler_disc='ExponentialLR', lr_scheduler_disc_params={'gamma': 0.999875, 'last_epoch': -1}, kl_loss_alpha=1.0, disc_loss_alpha=1.0, gen_loss_alpha=1.0, feat_loss_alpha=1.0, mel_loss_alpha=45.0, dur_loss_alpha=1.0, speaker_encoder_loss_alpha=1.0, return_wav=True, use_weighted_sampler=False, weighted_sampler_attrs={}, weighted_sampler_multipliers={}, r=1, num_speakers=0, use_speaker_embedding=False, speakers_file=None, speaker_embedding_channels=256, language_ids_file=None, use_language_embedding=False, use_d_vector_file=False, d_vector_file=None, d_vector_dim=0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "output_path = \"/Users/neil/Code/TTS_GI/outputs\"\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    meta_file_train=\"metadata.csv\",\n",
    "    path=\"/Users/neil/Code/TTS_GI/dataset\",\n",
    ")\n",
    "\n",
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=16000,\n",
    "    win_length=1024,\n",
    "    hop_length=256,\n",
    "    num_mels=80,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=None,\n",
    ")\n",
    "\n",
    "config = VitsConfig(\n",
    "    audio=audio_config,\n",
    "    run_name=\"VITS_Kamisato_Ayaka\",\n",
    "    run_description=\"VITS Kamisato Ayaka / Genshin Impact\",\n",
    "    batch_size=16,\n",
    "    eval_batch_size=16,\n",
    "    batch_group_size=1,\n",
    "    num_loader_workers=8,\n",
    "    num_eval_loader_workers=8,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=1,\n",
    "    text_cleaner=\"chinese_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"zn-ch\",\n",
    "    phoneme_cache_path=None,\n",
    "    compute_input_seq_cache=True,\n",
    "    print_step=1,\n",
    "    print_eval=True,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    cudnn_benchmark=True,\n",
    "    use_noise_augment=True,\n",
    "    test_sentences=[\n",
    "        [\"你好啊，小唐，你今天过的开心么？\"],\n",
    "        [\"好久没有联系啦，你最近还好吗？\"],\n",
    "        [\"我最近在学习新的技术，感觉很有趣。\"],\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.utils.synthesizer import Synthesizer\n",
    "import soundfile as sf\n",
    "\n",
    "model_path = \"best_model.pth\"\n",
    "config_path = \"config.json\"\n",
    "\n",
    "synthesizer =  Synthesizer(model_path, config_path)\n",
    "\n",
    "text = \"今天也是喜欢小唐的一天奥。\"\n",
    "\n",
    "wav = synthesizer.tts(text)\n",
    "sf.write(\"output.wav\", wav, 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminal Generate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tts --text \"今天也是喜欢小唐的一天。\" \\\n",
    "    --model_name \"tts_models/zh-CN/baker/tacotron2-DDC-GST\" \\\n",
    "    --out_path \"test_outputs_termial.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Generate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/neil/Library/Application Support/tts/tts_models--zh-CN--baker--tacotron2-DDC-GST/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Text splitted to sentences.\n",
      "['今天也是喜欢小唐的一天。']\n",
      " > Processing time: 0.6954970359802246\n",
      " > Real-time factor: 0.25163608629830586\n"
     ]
    }
   ],
   "source": [
    "from TTS.utils.synthesizer import Synthesizer\n",
    "import soundfile as sf\n",
    "\n",
    "model_path = \"model_file.pth\"\n",
    "config_path = \"config copy.json\"\n",
    "\n",
    "synthesizer =  Synthesizer(model_path, config_path)\n",
    "\n",
    "text = \"今天也是喜欢小唐的一天。\"\n",
    "\n",
    "wav = synthesizer.tts(text)\n",
    "sf.write(\"test_outputs_python.wav\", wav, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/neil/Library/Application Support/tts/tts_models--zh-CN--baker--tacotron2-DDC-GST/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TTS' object has no attribute 'is_multi_lingual'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#tts = TTS(model_name=\"tts_models/zh-CN/baker/tacotron2-DDC-GST\", progress_bar=True)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tts \u001b[38;5;241m=\u001b[39m TTS(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_file.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig copy.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtts_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m今天也是喜欢小唐的一天。\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_outputs_python_api.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/TTS_GI/lib/python3.10/site-packages/TTS/api.py:332\u001b[0m, in \u001b[0;36mTTS.tts_to_file\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, pipe_out, file_path, split_sentences, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtts_to_file\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    302\u001b[0m ):\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m            Additional arguments for the model.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts(\n\u001b[1;32m    335\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m    336\u001b[0m         speaker\u001b[38;5;241m=\u001b[39mspeaker,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer\u001b[38;5;241m.\u001b[39msave_wav(wav\u001b[38;5;241m=\u001b[39mwav, path\u001b[38;5;241m=\u001b[39mfile_path, pipe_out\u001b[38;5;241m=\u001b[39mpipe_out)\n",
      "File \u001b[0;32m~/miniconda3/envs/TTS_GI/lib/python3.10/site-packages/TTS/api.py:228\u001b[0m, in \u001b[0;36mTTS._check_arguments\u001b[0;34m(self, speaker, language, speaker_wav, emotion, speed, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_speaker \u001b[38;5;129;01mand\u001b[39;00m (speaker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m speaker_wav \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is multi-speaker but no `speaker` is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_multi_lingual\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m language \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is multi-lingual but no `language` is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_speaker \u001b[38;5;129;01mand\u001b[39;00m speaker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/miniconda3/envs/TTS_GI/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TTS' object has no attribute 'is_multi_lingual'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "#tts = TTS(model_name=\"tts_models/zh-CN/baker/tacotron2-DDC-GST\", progress_bar=True)\n",
    "tts = TTS(model_path=\"model_file.pth\", config_path=\"config copy.json\", progress_bar=True, gpu=False)\n",
    "tts.tts_to_file(text=\"今天也是喜欢小唐的一天。\", file_path=\"test_outputs_python_api.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TTS_GI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
